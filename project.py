import queue
import sys
import json
import pyaudio
import vosk
import re
import os

# í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
KEYWORDS = ["ì•ˆë…•", "ì œíŠ¸ìŠ¨", "ìŒì„± ì¸ì‹", "ì‹œì‘"]

# í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ Python íŒŒì¼ì˜ ë””ë ‰í† ë¦¬
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_PATH = os.path.join(BASE_DIR, "vosk-model-small-ko-0.22")

# Vosk ëª¨ë¸ ë¡œë“œ
model = vosk.Model(MODEL_PATH)
recognizer = vosk.KaldiRecognizer(model, 16000)

# ì˜¤ë””ì˜¤ ì…ë ¥ ë²„í¼
audio_queue = queue.Queue()


def audio_callback(in_data, frame_count, time_info, status):
    """ì˜¤ë””ì˜¤ ì½œë°± í•¨ìˆ˜"""
    audio_queue.put(in_data)
    return (None, pyaudio.paContinue)


# PyAudio ì„¤ì •
p = pyaudio.PyAudio()
stream = p.open(
    format=pyaudio.paInt16,
    channels=1,
    rate=16000,
    input=True,
    frames_per_buffer=8000,
    stream_callback=audio_callback,
)

print("ğŸ™ï¸ ìŒì„± ì¸ì‹ ì‹œì‘... (Ctrl+Cë¡œ ì¢…ë£Œ)")
stream.start_stream()

try:
    while True:
        if not audio_queue.empty():
            data = audio_queue.get()
            if recognizer.AcceptWaveform(data):
                result = json.loads(recognizer.Result())
                text = result.get("text", "")
                if text:
                    print(f"ğŸ—£ï¸ ì¸ì‹ëœ í…ìŠ¤íŠ¸: {text}")

                    # í‚¤ì›Œë“œ ê²€ìƒ‰
                    for keyword in KEYWORDS:
                        if re.search(rf"\b{keyword}\b", text):
                            print(f"ğŸ” í‚¤ì›Œë“œ '{keyword}' ê°ì§€ë¨!")

except KeyboardInterrupt:
    print("\nğŸ›‘ ìŒì„± ì¸ì‹ ì¢…ë£Œ")
finally:
    stream.stop_stream()
    stream.close()
    p.terminate()
